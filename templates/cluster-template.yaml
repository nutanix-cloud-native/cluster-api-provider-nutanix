apiVersion: v1
binaryData:
  ca.crt: ${NUTANIX_ADDITIONAL_TRUST_BUNDLE=""}
kind: ConfigMap
metadata:
  name: user-ca-bundle
  namespace: ${NAMESPACE}
---
apiVersion: v1
kind: Secret
metadata:
  name: ${CLUSTER_NAME}
  namespace: ${NAMESPACE}
stringData:
  credentials: "[\n  {\n    \"type\": \"basic_auth\", \n    \"data\": { \n      \"prismCentral\":{\n
    \       \"username\": \"${NUTANIX_USER}\", \n        \"password\": \"${NUTANIX_PASSWORD}\"\n
    \     }\n    }\n  }\n]\n"
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: ${CLUSTER_NAME}-kcfg-0
  namespace: ${NAMESPACE}
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            eviction-hard: nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%
            tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
      postKubeadmCommands:
      - echo "after kubeadm call" > /var/log/postkubeadm.log
      preKubeadmCommands:
      - echo "before kubeadm call" > /var/log/prekubeadm.log
      - hostnamectl set-hostname "{{ ds.meta_data.hostname }}"
      users:
      - lockPassword: false
        name: capiuser
        sshAuthorizedKeys:
        - ${NUTANIX_SSH_AUTHORIZED_KEY}
        sudo: ALL=(ALL) NOPASSWD:ALL
      verbosity: 10
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  name: ${CLUSTER_NAME}
  namespace: ${NAMESPACE}
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 172.20.0.0/16
    serviceDomain: cluster.local
    services:
      cidrBlocks:
      - 172.19.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: ${CLUSTER_NAME}-kcp
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: NutanixCluster
    name: ${CLUSTER_NAME}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  name: ${CLUSTER_NAME}-wmd
  namespace: ${NAMESPACE}
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WORKER_MACHINE_COUNT}
  selector:
    matchLabels: {}
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: ${CLUSTER_NAME}-kcfg-0
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: NutanixMachineTemplate
        name: ${CLUSTER_NAME}-mt-0
      version: ${KUBERNETES_VERSION}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineHealthCheck
metadata:
  name: ${CLUSTER_NAME}-mhc
  namespace: ${NAMESPACE}
spec:
  clusterName: ${CLUSTER_NAME}
  maxUnhealthy: 40%
  nodeStartupTimeout: 10m
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  unhealthyConditions:
  - status: "False"
    timeout: 300s
    type: Ready
  - status: Unknown
    timeout: 300s
    type: Ready
  - status: "True"
    timeout: 300s
    type: MemoryPressure
  - status: "True"
    timeout: 300s
    type: DiskPressure
  - status: "True"
    timeout: 300s
    type: PIDPressure
  - status: "True"
    timeout: 300s
    type: NetworkUnavailable
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: ${CLUSTER_NAME}-kcp
  namespace: ${NAMESPACE}
spec:
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        certSANs:
        - localhost
        - 127.0.0.1
        - 0.0.0.0
        extraArgs:
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
      controllerManager:
        extraArgs:
          enable-hostpath-provisioner: "true"
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
      scheduler:
        extraArgs:
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
    files:
    - content: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-vip
          namespace: kube-system
        spec:
          containers:
            - name: kube-vip
              image: ghcr.io/kube-vip/kube-vip:v0.5.11
              imagePullPolicy: IfNotPresent
              args:
                - manager
              env:
                - name: vip_arp
                  value: "true"
                - name: address
                  value: "${CONTROL_PLANE_ENDPOINT_IP}"
                - name: port
                  value: "${CONTROL_PLANE_ENDPOINT_PORT=6443}"
                - name: vip_cidr
                  value: "32"
                - name: cp_enable
                  value: "true"
                - name: cp_namespace
                  value: kube-system
                - name: vip_ddns
                  value: "false"
                - name: vip_leaderelection
                  value: "true"
                - name: vip_leaseduration
                  value: "15"
                - name: vip_renewdeadline
                  value: "10"
                - name: vip_retryperiod
                  value: "2"
                - name: svc_enable
                  value: "${KUBEVIP_SVC_ENABLE=false}"
                - name: lb_enable
                  value: "${KUBEVIP_LB_ENABLE=false}"
                - name: enableServicesElection
                  value: "${KUBEVIP_SVC_ELECTION=false}"
              securityContext:
                capabilities:
                  add:
                    - NET_ADMIN
                    - SYS_TIME
                    - NET_RAW
              volumeMounts:
                - mountPath: /etc/kubernetes/admin.conf
                  name: kubeconfig
              resources: {}
          hostNetwork: true
          hostAliases:
            - hostnames:
                - kubernetes
              ip: 127.0.0.1
          volumes:
            - name: kubeconfig
              hostPath:
                type: FileOrCreate
                path: /etc/kubernetes/admin.conf
        status: {}
      owner: root:root
      path: /etc/kubernetes/manifests/kube-vip.yaml
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          eviction-hard: nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          eviction-hard: nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
    postKubeadmCommands:
    - echo export KUBECONFIG=/etc/kubernetes/admin.conf >> /root/.bashrc
    - echo "after kubeadm call" > /var/log/postkubeadm.log
    preKubeadmCommands:
    - echo "before kubeadm call" > /var/log/prekubeadm.log
    - hostnamectl set-hostname "{{ ds.meta_data.hostname }}"
    useExperimentalRetryJoin: true
    users:
    - lockPassword: false
      name: capiuser
      sshAuthorizedKeys:
      - ${NUTANIX_SSH_AUTHORIZED_KEY}
      sudo: ALL=(ALL) NOPASSWD:ALL
    verbosity: 10
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: NutanixMachineTemplate
      name: ${CLUSTER_NAME}-mt-0
  replicas: ${CONTROL_PLANE_MACHINE_COUNT=1}
  version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixCluster
metadata:
  name: ${CLUSTER_NAME}
  namespace: ${NAMESPACE}
spec:
  controlPlaneEndpoint:
    host: ${CONTROL_PLANE_ENDPOINT_IP}
    port: ${CONTROL_PLANE_ENDPOINT_PORT=6443}
  prismCentral:
    additionalTrustBundle:
      kind: ConfigMap
      name: user-ca-bundle
    address: ${NUTANIX_ENDPOINT}
    credentialRef:
      kind: Secret
      name: ${CLUSTER_NAME}
    insecure: ${NUTANIX_INSECURE=false}
    port: ${NUTANIX_PORT=9440}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-mt-0
  namespace: ${NAMESPACE}
spec:
  template:
    spec:
      bootType: ${NUTANIX_MACHINE_BOOT_TYPE=legacy}
      cluster:
        name: ${NUTANIX_PRISM_ELEMENT_CLUSTER_NAME}
        type: name
      image:
        name: ${NUTANIX_MACHINE_TEMPLATE_IMAGE_NAME}
        type: name
      memorySize: ${NUTANIX_MACHINE_MEMORY_SIZE=4Gi}
      providerID: nutanix://${CLUSTER_NAME}-m1
      subnet:
      - name: ${NUTANIX_SUBNET_NAME}
        type: name
      systemDiskSize: ${NUTANIX_SYSTEMDISK_SIZE=40Gi}
      vcpuSockets: ${NUTANIX_MACHINE_VCPU_SOCKET=2}
      vcpusPerSocket: ${NUTANIX_MACHINE_VCPU_PER_SOCKET=1}
