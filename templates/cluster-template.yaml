apiVersion: v1
binaryData:
  ca.crt: ${NUTANIX_ADDITIONAL_TRUST_BUNDLE=""}
kind: ConfigMap
metadata:
  name: ${CLUSTER_NAME}-pc-trusted-ca-bundle
  namespace: ${NAMESPACE}
---
apiVersion: v1
data:
  nutanix-ccm-cm.yaml: |-
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: nutanix-ccm-pc-trusted-ca-bundle
      namespace: kube-system
    binaryData:
      ca.crt: ${NUTANIX_ADDITIONAL_TRUST_BUNDLE=""}
  nutanix-ccm.yaml: |
    ---
    # Source: nutanix-cloud-provider/templates/rbac.yaml
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: cloud-controller-manager
      namespace: kube-system
    ---
    # Source: nutanix-cloud-provider/templates/rbac.yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      annotations:
        rbac.authorization.kubernetes.io/autoupdate: "true"
      name: system:cloud-controller-manager
    rules:
      - apiGroups:
          - ""
        resources:
          - secrets
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - ""
        resources:
          - configmaps
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - ""
        resources:
          - events
        verbs:
          - create
          - patch
          - update
      - apiGroups:
          - ""
        resources:
          - nodes
        verbs:
          - "*"
      - apiGroups:
          - ""
        resources:
          - nodes/status
        verbs:
          - patch
      - apiGroups:
          - ""
        resources:
          - serviceaccounts
        verbs:
          - create
      - apiGroups:
          - ""
        resources:
          - endpoints
        verbs:
          - create
          - get
          - list
          - watch
          - update
      - apiGroups:
          - coordination.k8s.io
        resources:
          - leases
        verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
    ---
    # Source: nutanix-cloud-provider/templates/rbac.yaml
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: system:cloud-controller-manager
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: system:cloud-controller-manager
    subjects:
      - kind: ServiceAccount
        name: cloud-controller-manager
        namespace: kube-system
    ---
    # Source: nutanix-cloud-provider/templates/cloud-provider-nutanix-deployment.yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        k8s-app: nutanix-cloud-controller-manager
      name: nutanix-cloud-controller-manager
      namespace: kube-system
    spec:
      replicas: 1
      selector:
        matchLabels:
          k8s-app: nutanix-cloud-controller-manager
      strategy:
        type: Recreate
      template:
        metadata:
          labels:
            k8s-app: nutanix-cloud-controller-manager
        spec:
          hostNetwork: true
          priorityClassName: system-cluster-critical
          nodeSelector:
            node-role.kubernetes.io/control-plane: ""
          serviceAccountName: cloud-controller-manager
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchLabels:
                    k8s-app: nutanix-cloud-controller-manager
                topologyKey: kubernetes.io/hostname
          dnsPolicy: Default
          tolerations:
            - effect: NoSchedule
              key: node-role.kubernetes.io/master
              operator: Exists
            - effect: NoSchedule
              key: node-role.kubernetes.io/control-plane
              operator: Exists
            - effect: NoExecute
              key: node.kubernetes.io/unreachable
              operator: Exists
              tolerationSeconds: 120
            - effect: NoExecute
              key: node.kubernetes.io/not-ready
              operator: Exists
              tolerationSeconds: 120
            - effect: NoSchedule
              key: node.cloudprovider.kubernetes.io/uninitialized
              operator: Exists
            - effect: NoSchedule
              key: node.kubernetes.io/not-ready
              operator: Exists
          containers:
            - image: "${CCM_REPO=ghcr.io/nutanix-cloud-native/cloud-provider-nutanix/controller}:${CCM_TAG=v0.3.2}"
              imagePullPolicy: IfNotPresent
              name: nutanix-cloud-controller-manager
              env:
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
              args:
                - "--leader-elect=true"
                - "--cloud-config=/etc/cloud/nutanix_config.json"
              resources:
                requests:
                  cpu: 100m
                  memory: 50Mi
              volumeMounts:
                - mountPath: /etc/cloud
                  name: nutanix-config-volume
                  readOnly: true
          volumes:
            - name: nutanix-config-volume
              configMap:
                name: nutanix-config
kind: ConfigMap
metadata:
  name: nutanix-ccm
  namespace: ${NAMESPACE}
---
apiVersion: v1
data:
  nutanix_config.json: |-
    {
        "prismCentral": {
        "address": "${NUTANIX_ENDPOINT}",
        "port": ${NUTANIX_PORT=9440},
        "insecure": ${NUTANIX_INSECURE=false},
        "credentialRef": {
            "kind": "secret",
            "name": "nutanix-creds",
            "namespace": "kube-system"
        },
        "additionalTrustBundle": {
            "kind": "ConfigMap",
            "name": "${CLUSTER_NAME}-pc-trusted-ca-bundle",
            "namespace": "kube-system"
        }
        },
        "enableCustomLabeling": ${CCM_CUSTOM_LABEL=false},
        "topologyDiscovery": {
        "type": "Prism"
        }
    }
kind: ConfigMap
metadata:
  name: nutanix-config
  namespace: ${NAMESPACE}
---
apiVersion: v1
kind: Secret
metadata:
  name: ${CLUSTER_NAME}
  namespace: ${NAMESPACE}
stringData:
  credentials: |
    [
      {
        "type": "basic_auth",
        "data": {
          "prismCentral":{
            "username": "${NUTANIX_USER}",
            "password": "${NUTANIX_PASSWORD}"
          }
        }
      }
    ]
---
apiVersion: v1
kind: Secret
metadata:
  name: nutanix-ccm-secret
  namespace: ${NAMESPACE}
stringData:
  nutanix-ccm-secret.yaml: |
    apiVersion: v1
    kind: Secret
    metadata:
      name: nutanix-creds
      namespace: kube-system
    stringData:
      credentials: |
        [
          {
            "type": "basic_auth",
            "data": {
              "prismCentral":{
                "username": "${NUTANIX_USER}",
                "password": "${NUTANIX_PASSWORD}"
              },
              "prismElements": null
            }
          }
        ]
type: addons.cluster.x-k8s.io/resource-set
---
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: nutanix-ccm-crs
  namespace: ${NAMESPACE}
spec:
  clusterSelector:
    matchLabels:
      ccm: nutanix
  resources:
  - kind: ConfigMap
    name: nutanix-ccm
  - kind: Secret
    name: nutanix-ccm-secret
  - kind: ConfigMap
    name: nutanix-ccm-pc-trusted-ca-bundle
  strategy: ApplyOnce
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: ${CLUSTER_NAME}-kcfg-0
  namespace: ${NAMESPACE}
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            cloud-provider: external
            eviction-hard: nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<15%,memory.available<100Mi,imagefs.inodesFree<10%
            tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
      postKubeadmCommands:
      - echo "after kubeadm call" > /var/log/postkubeadm.log
      preKubeadmCommands:
      - echo "before kubeadm call" > /var/log/prekubeadm.log
      - hostnamectl set-hostname "{{ ds.meta_data.hostname }}"
      users:
      - lockPassword: false
        name: capiuser
        sshAuthorizedKeys:
        - ${NUTANIX_SSH_AUTHORIZED_KEY}
        sudo: ALL=(ALL) NOPASSWD:ALL
      verbosity: 10
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    ccm: nutanix
    cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  name: ${CLUSTER_NAME}
  namespace: ${NAMESPACE}
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 172.20.0.0/16
    serviceDomain: cluster.local
    services:
      cidrBlocks:
      - 172.19.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: ${CLUSTER_NAME}-kcp
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: NutanixCluster
    name: ${CLUSTER_NAME}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  name: ${CLUSTER_NAME}-wmd
  namespace: ${NAMESPACE}
spec:
  clusterName: ${CLUSTER_NAME}
  replicas: ${WORKER_MACHINE_COUNT}
  selector:
    matchLabels: {}
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: ${CLUSTER_NAME}-kcfg-0
      clusterName: ${CLUSTER_NAME}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: NutanixMachineTemplate
        name: ${CLUSTER_NAME}-mt-0
      version: ${KUBERNETES_VERSION}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineHealthCheck
metadata:
  name: ${CLUSTER_NAME}-mhc
  namespace: ${NAMESPACE}
spec:
  clusterName: ${CLUSTER_NAME}
  maxUnhealthy: 40%
  nodeStartupTimeout: 10m0s
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  unhealthyConditions:
  - status: "False"
    timeout: 5m0s
    type: Ready
  - status: Unknown
    timeout: 5m0s
    type: Ready
  - status: "True"
    timeout: 5m0s
    type: MemoryPressure
  - status: "True"
    timeout: 5m0s
    type: DiskPressure
  - status: "True"
    timeout: 5m0s
    type: PIDPressure
  - status: "True"
    timeout: 5m0s
    type: NetworkUnavailable
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: ${CLUSTER_NAME}-kcp
  namespace: ${NAMESPACE}
spec:
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        certSANs:
        - localhost
        - 127.0.0.1
        - 0.0.0.0
        extraArgs:
          cloud-provider: external
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
      controllerManager:
        extraArgs:
          cloud-provider: external
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
      scheduler:
        extraArgs:
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
    files:
    - content: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-vip
          namespace: kube-system
        spec:
          containers:
            - name: kube-vip
              image: ghcr.io/kube-vip/kube-vip:v0.6.4
              imagePullPolicy: IfNotPresent
              args:
                - manager
              env:
                - name: vip_arp
                  value: "true"
                - name: address
                  value: "${CONTROL_PLANE_ENDPOINT_IP}"
                - name: port
                  value: "${CONTROL_PLANE_ENDPOINT_PORT=6443}"
                - name: vip_cidr
                  value: "32"
                - name: cp_enable
                  value: "true"
                - name: cp_namespace
                  value: kube-system
                - name: vip_ddns
                  value: "false"
                - name: vip_leaderelection
                  value: "true"
                - name: vip_leaseduration
                  value: "15"
                - name: vip_renewdeadline
                  value: "10"
                - name: vip_retryperiod
                  value: "2"
                - name: svc_enable
                  value: "${KUBEVIP_SVC_ENABLE=false}"
                - name: lb_enable
                  value: "${KUBEVIP_LB_ENABLE=false}"
                - name: enableServicesElection
                  value: "${KUBEVIP_SVC_ELECTION=false}"
              securityContext:
                capabilities:
                  add:
                    - NET_ADMIN
                    - SYS_TIME
                    - NET_RAW
              volumeMounts:
                - mountPath: /etc/kubernetes/admin.conf
                  name: kubeconfig
              resources: {}
          hostNetwork: true
          volumes:
            - name: kubeconfig
              hostPath:
                type: FileOrCreate
                path: /etc/kubernetes/admin.conf
        status: {}
      owner: root:root
      path: /etc/kubernetes/manifests/kube-vip.yaml
    initConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          cloud-provider: external
          eviction-hard: nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<15%,memory.available<100Mi,imagefs.inodesFree<10%
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
    joinConfiguration:
      nodeRegistration:
        kubeletExtraArgs:
          cloud-provider: external
          eviction-hard: nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<15%,memory.available<100Mi,imagefs.inodesFree<10%
          tls-cipher-suites: ${TLS_CIPHER_SUITES=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256}
    postKubeadmCommands:
    - echo export KUBECONFIG=/etc/kubernetes/admin.conf >> /root/.bashrc
    - |
      KUBERNETES_VERSION_NO_V=${KUBERNETES_VERSION#v}
      VERSION_TO_COMPARE=1.29.0
      if [ "$(printf '%s\n' "$KUBERNETES_VERSION_NO_V" "$VERSION_TO_COMPARE" | sort -V | head -n1)" != "$KUBERNETES_VERSION_NO_V" ]; then
        if [ -f /run/kubeadm/kubeadm.yaml ]; then
          sed -i 's#path: /etc/kubernetes/super-admin.conf#path: /etc/kubernetes/admin.conf#' /etc/kubernetes/manifests/kube-vip.yaml;
        fi
      fi
    - echo "after kubeadm call" > /var/log/postkubeadm.log
    preKubeadmCommands:
    - echo "before kubeadm call" > /var/log/prekubeadm.log
    - hostnamectl set-hostname "{{ ds.meta_data.hostname }}"
    - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
    - echo "127.0.0.1   localhost" >>/etc/hosts
    - echo "127.0.0.1   kubernetes" >>/etc/hosts
    - echo "127.0.0.1   {{ ds.meta_data.hostname }}" >> /etc/hosts
    - |
      KUBERNETES_VERSION_NO_V=${KUBERNETES_VERSION#v}
      VERSION_TO_COMPARE=1.29.0
      if [ "$(printf '%s\n' "$KUBERNETES_VERSION_NO_V" "$VERSION_TO_COMPARE" | sort -V | head -n1)" != "$KUBERNETES_VERSION_NO_V" ]; then
        if [ -f /run/kubeadm/kubeadm.yaml ]; then
          sed -i 's#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#' /etc/kubernetes/manifests/kube-vip.yaml;
        fi
      fi
    useExperimentalRetryJoin: true
    users:
    - lockPassword: false
      name: capiuser
      sshAuthorizedKeys:
      - ${NUTANIX_SSH_AUTHORIZED_KEY}
      sudo: ALL=(ALL) NOPASSWD:ALL
    verbosity: 10
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: NutanixMachineTemplate
      name: ${CLUSTER_NAME}-mt-0
  replicas: ${CONTROL_PLANE_MACHINE_COUNT=1}
  version: ${KUBERNETES_VERSION}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixCluster
metadata:
  name: ${CLUSTER_NAME}
  namespace: ${NAMESPACE}
spec:
  controlPlaneEndpoint:
    host: ${CONTROL_PLANE_ENDPOINT_IP}
    port: ${CONTROL_PLANE_ENDPOINT_PORT=6443}
  prismCentral:
    additionalTrustBundle:
      kind: ConfigMap
      name: ${CLUSTER_NAME}-pc-trusted-ca-bundle
    address: ${NUTANIX_ENDPOINT}
    credentialRef:
      kind: Secret
      name: ${CLUSTER_NAME}
    insecure: ${NUTANIX_INSECURE=false}
    port: ${NUTANIX_PORT=9440}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixMachineTemplate
metadata:
  name: ${CLUSTER_NAME}-mt-0
  namespace: ${NAMESPACE}
spec:
  template:
    spec:
      bootType: ${NUTANIX_MACHINE_BOOT_TYPE=legacy}
      cluster:
        name: ${NUTANIX_PRISM_ELEMENT_CLUSTER_NAME}
        type: name
      image:
        name: ${NUTANIX_MACHINE_TEMPLATE_IMAGE_NAME}
        type: name
      memorySize: ${NUTANIX_MACHINE_MEMORY_SIZE=4Gi}
      providerID: nutanix://${CLUSTER_NAME}-m1
      subnet:
      - name: ${NUTANIX_SUBNET_NAME}
        type: name
      systemDiskSize: ${NUTANIX_SYSTEMDISK_SIZE=40Gi}
      vcpuSockets: ${NUTANIX_MACHINE_VCPU_SOCKET=2}
      vcpusPerSocket: ${NUTANIX_MACHINE_VCPU_PER_SOCKET=1}
